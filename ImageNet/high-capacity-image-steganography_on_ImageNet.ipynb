{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport PIL\nimport random\nfrom scipy import ndimage\nimport glob\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision.datasets import CIFAR100,ImageNet\nfrom torchvision import transforms\nfrom time import time\nfrom skimage.data import astronaut,rocket\nfrom skimage.metrics import structural_similarity\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:08:17.658880Z","iopub.execute_input":"2022-07-13T09:08:17.659571Z","iopub.status.idle":"2022-07-13T09:08:48.923984Z","shell.execute_reply.started":"2022-07-13T09:08:17.659533Z","shell.execute_reply":"2022-07-13T09:08:48.922947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"addresses_t = glob.glob('../input/imagenetmini-1000/imagenet-mini/train/*/*.JPEG')\naddresses_v = glob.glob('../input/imagenetmini-1000/imagenet-mini/val/*/ILSVRC2012_val_*.JPEG')       \ntrain_addressess=[]\nval_addressess=[]\nfor x in addresses_t:\n    img = Image.open(x)\n    img_shape = transforms.ToTensor()(img).size()\n    if ((img_shape[0] == 1) or (img_shape[1] < 256) or (img_shape[2] < 256)):\n        pass\n    else:\n        train_addressess.append(x)\n        \n        \nwith open('address_train.txt', 'w') as f:\n    for line in train_addressess:\n        f.write(line)\n        f.write('\\n')\nf.close()        \n                       \nfor x in addresses_v:\n    img = Image.open(x)\n    img_shape = transforms.ToTensor()(img).size()\n    if ((img_shape[0] == 1) or (img_shape[1] < 256) or (img_shape[2] < 256)):\n        pass\n    else:\n        val_addressess.append(x)\n        \nwith open('address_test.txt', 'w') as f:\n    for line in val_addressess:\n        f.write(line)\n        f.write('\\n')\nf.close()                ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:21:03.496708Z","iopub.execute_input":"2022-07-03T11:21:03.497054Z","iopub.status.idle":"2022-07-03T11:30:00.552152Z","shell.execute_reply.started":"2022-07-03T11:21:03.497019Z","shell.execute_reply":"2022-07-03T11:30:00.550824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/image-net-steganography/address_train_carrier.txt','r') as f:\n    train_addresses_carrier = f.readlines() \nf.close()        \nwith open('../input/image-net-steganography/address_train_secret.txt','r') as f:\n    train_addresses_secret = f.readlines() \nf.close()  \nwith open('../input/image-net-steganography/address_test_carrier.txt','r') as f:\n    test_addresses_carrier = f.readlines() \nf.close()   \nwith open('../input/image-net-steganography/address_test_secret.txt','r') as f:\n    test_addresses_secret = f.readlines() \nf.close()   ","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:28.174059Z","iopub.execute_input":"2022-07-13T06:09:28.174332Z","iopub.status.idle":"2022-07-13T06:09:28.248490Z","shell.execute_reply.started":"2022-07-13T06:09:28.174286Z","shell.execute_reply":"2022-07-13T06:09:28.247786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_addresses_carrier[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T10:59:27.100139Z","iopub.execute_input":"2022-07-03T10:59:27.100443Z","iopub.status.idle":"2022-07-03T10:59:27.109709Z","shell.execute_reply.started":"2022-07-03T10:59:27.100413Z","shell.execute_reply":"2022-07-03T10:59:27.108958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class train_Dataset(torch.utils.data.Dataset):\n#     def __init__(self):\n#         super(train_Dataset, self).__init__()\n# #         self.paths_train=glob.glob('../input/imagenet/imagenet/train/ILSVRC2012_val_*.JPEG')\n#         self.paths_train=train_addresses\n#         self.paths_train.sort()\n#         self.data_files =self.paths_train\n        \n#     def __getitem__(self,idx):\n#         x =Image.open(self.data_files[idx].rstrip())\n#         x_tensor = transforms.ToTensor()(x)\n#         x_resized=x_tensor[:,0:256,0:256]\n#         return x_resized \n# #         x =np.array(Image.open(self.data_files[idx]))\n# #         x_resized=x[0:255,0:255]\n# #         x_tensor = torch.from_numpy(x_resized)\n# #         x_tensor = x_tensor.permute(2,0,1)\n#     #         x_tensor = F.normalize(x_tensor)\n          \n#     def __len__(self):\n#         return len(self.data_files)\n    \n# class test_Dataset(torch.utils.data.Dataset):\n#     def __init__(self):\n#         super(test_Dataset, self).__init__()\n# #         self.paths_test=glob.glob('../input/imagenet/imagenet/val/ILSVRC2012_val_*.JPEG')\n#         self.paths_test=test_addresses\n#         self.paths_test.sort()\n# #         for x in self.paths_test :\n# #             img = Image.open(x)\n# #             img_shape = transforms.ToTensor()(img).size()\n# #             if img_shape[0] == 1:\n# #                 pass\n# #             else:\n#         self.data_files = self.paths_test\n#     def __getitem__(self,idx):\n#         x =Image.open(self.data_files[idx].rstrip())\n#         x_tensor = transforms.ToTensor()(x)\n#         x_resized=x_tensor[:,0:256,0:256]\n#         return x_resized\n    \n# #         x_tensor = torch.from_numpy(x_resized)\n# #         x_tensor = x_tensor.permute(2,0,1)\n#     #         x_tensor = F.normalize(x_tensor) \n#     def __len__(self):\n#         return len(self.data_files)\n\n\n\nclass train_Dataset(torch.utils.data.Dataset):\n    def __init__(self):\n        super(train_Dataset, self).__init__()\n        self.paths_train_carrier=train_addresses_carrier\n        self.paths_train_carrier.sort()\n        self.data_files_carrier =self.paths_train_carrier\n        self.paths_train_secret=train_addresses_secret\n        self.paths_train_secret.sort()\n        self.data_files_secret =self.paths_train_secret\n        \n    def __getitem__(self,idx):\n        x =Image.open(self.data_files_carrier[idx].rstrip())\n        x_tensor = transforms.ToTensor()(x)\n        carrier=x_tensor[:,0:256,0:256]\n        y =Image.open(self.data_files_secret[idx].rstrip())\n        y_tensor = transforms.ToTensor()(y)\n        secret=y_tensor[:,0:256,0:256]\n        return carrier , secret \n          \n    def __len__(self):\n        return len(self.data_files_secret)\n    \nclass test_Dataset(torch.utils.data.Dataset):\n    def __init__(self):\n        super(test_Dataset, self).__init__()\n        self.paths_test_carrier=test_addresses_carrier\n        self.paths_test_carrier.sort()\n        self.data_files_carrier =self.paths_test_carrier\n        self.paths_test_secret=test_addresses_secret\n        self.paths_test_secret.sort()\n        self.data_files_secret =self.paths_test_secret\n        \n    def __getitem__(self,idx):\n        x =Image.open(self.data_files_carrier[idx].rstrip())\n        x_tensor = transforms.ToTensor()(x)\n        carrier=x_tensor[:,0:256,0:256]\n        y =Image.open(self.data_files_secret[idx].rstrip())\n        y_tensor = transforms.ToTensor()(y)\n        secret=y_tensor[:,0:256,0:256]\n        return carrier , secret \n          \n    def __len__(self):\n        return len(self.data_files_secret)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:32.367399Z","iopub.execute_input":"2022-07-13T06:09:32.367813Z","iopub.status.idle":"2022-07-13T06:09:32.385040Z","shell.execute_reply.started":"2022-07-13T06:09:32.367779Z","shell.execute_reply":"2022-07-13T06:09:32.384346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class train_Dataset(torch.utils.data.Dataset):\n#     def __init__(self):\n#         super(train_Dataset, self).__init__()\n#         self.paths_train=train_addresses\n#         self.paths_train.sort()\n#         self.data_files =self.paths_train\n        \n#     def __getitem__(self,idx):\n#         x =Image.open(self.data_files[idx].rstrip())\n#         x_tensor = transforms.ToTensor()(x)\n#         x_resized=x_tensor[:,0:256,0:256]\n#         return x_resized \n          \n#     def __len__(self):\n#         return len(self.data_files)\n    \n# class test_Dataset(torch.utils.data.Dataset):\n#     def __init__(self):\n#         super(test_Dataset, self).__init__()\n#         self.paths_test=test_addresses\n#         self.paths_test.sort()\n#         self.data_files = self.paths_test\n#     def __getitem__(self,idx):\n#         x =Image.open(self.data_files[idx].rstrip())\n# #         y =Image.open(self.data_files[idx].rstrip()) \n#         x_tensor = transforms.ToTensor()(x)\n#         x_resized=x_tensor[:,0:256,0:256]\n#         return x_resized\n#     def __len__(self):\n#         return len(self.data_files)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T17:50:57.935884Z","iopub.execute_input":"2022-07-04T17:50:57.936209Z","iopub.status.idle":"2022-07-04T17:50:57.947472Z","shell.execute_reply.started":"2022-07-04T17:50:57.936175Z","shell.execute_reply":"2022-07-04T17:50:57.946349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=train_Dataset()\ntest_data=test_Dataset()\ntrain_loader = DataLoader(train_data, batch_size = 8, num_workers = 0)\ntest_loader = DataLoader(test_data, batch_size = 16, num_workers = 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:05:42.467682Z","iopub.execute_input":"2022-07-13T09:05:42.468123Z","iopub.status.idle":"2022-07-13T09:05:42.475092Z","shell.execute_reply.started":"2022-07-13T09:05:42.468086Z","shell.execute_reply":"2022-07-13T09:05:42.474244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T12:11:23.287977Z","iopub.execute_input":"2022-07-11T12:11:23.288257Z","iopub.status.idle":"2022-07-11T12:11:23.293451Z","shell.execute_reply.started":"2022-07-11T12:11:23.288228Z","shell.execute_reply":"2022-07-11T12:11:23.292723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch_i, (carrier,secret) in enumerate(train_loader):\n    fig, ax = plt.subplots(1,2, figsize =(15,15))\n    ax[0].imshow(carrier[5].permute(1,2,0))\n    ax[1].imshow(secret[2].permute(1,2,0))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:31:34.481019Z","iopub.execute_input":"2022-07-11T14:31:34.481474Z","iopub.status.idle":"2022-07-11T14:31:35.303735Z","shell.execute_reply.started":"2022-07-11T14:31:34.481424Z","shell.execute_reply":"2022-07-11T14:31:35.302732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:29:59.347072Z","iopub.execute_input":"2022-07-11T14:29:59.347353Z","iopub.status.idle":"2022-07-11T14:29:59.353000Z","shell.execute_reply.started":"2022-07-11T14:29:59.347326Z","shell.execute_reply":"2022-07-11T14:29:59.352042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch_i, (carrier,secret) in enumerate(train_loader):\n    concatenated_input=torch.cat((carrier,secret),1)\n    print(carrier.shape)  \n    print(secret.shape)        \n    print(concatenated_input.shape)    \n    break","metadata":{"execution":{"iopub.status.busy":"2022-07-11T14:31:50.968543Z","iopub.execute_input":"2022-07-11T14:31:50.968827Z","iopub.status.idle":"2022-07-11T14:31:51.145580Z","shell.execute_reply.started":"2022-07-11T14:31:50.968799Z","shell.execute_reply":"2022-07-11T14:31:51.144910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ Defining classes which are used in Network #############\n\n############ DenseNet is composed of Single layers  #############\n\nclass SingleLayer(nn.Module):\n    def __init__(self, nChannels, growthRate):\n        super(SingleLayer, self).__init__()\n        self.bn     = nn.BatchNorm2d(nChannels)\n        self.conv   = nn.Conv2d(nChannels, growthRate, kernel_size=3,padding=1, bias=False)\n        self.relu   = nn.ReLU()\n        self.dropout = nn.Dropout2d(0.2)\n\n    def forward(self, x):\n        out = self.bn(x)\n        out = self.conv(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = torch.cat((x, out), 1)\n        return out\n####################################################################################################\n\n############ DenseNet is made by choosing number of layers and growth rate which is a constant output of each layer  #############\n\nclass DenseNet(nn.Module):\n  def __init__(self, nChannels, growthRate, nDenseBlocks):\n    super(DenseNet,self).__init__()\n    self.dense = self.make_dense(nChannels, growthRate, nDenseBlocks)\n  \n  def make_dense(self, nChannels, growthRate, nDenseBlocks):\n    layers = []\n    for i in range(int(nDenseBlocks)):\n        layers.append(SingleLayer(nChannels, growthRate))\n        nChannels += growthRate\n    return nn.Sequential(*layers)  \n\n  def forward(self,x):\n    out = self.dense(x)\n    return out\n\n\n####################################################################################################\n\n############ Transition down layer is used to reduce the number of feature maps  #############\n\nclass Transition_Down(nn.Module): \n  def __init__(self, input_channels,output_channels):\n    super(Transition_Down, self).__init__()\n    self.TD = nn.Sequential(nn.BatchNorm2d(input_channels),\n                            nn.ReLU(),\n                            nn.Conv2d(input_channels,output_channels,kernel_size=1,padding ='same'),\n                            nn.MaxPool2d(kernel_size=2,stride=2))\n    \n  def forward(self,x):\n    out = self.TD(x)\n    return out  \n    \n####################################################################################################\n\n############ Transition up layer is used to compensate the effect of transtion down layer which has reduce nemuber of feature maps  #############\n\nclass Transition_Up(nn.Module): \n  def __init__(self, input_channels,output_channels):\n    super(Transition_Up, self).__init__()\n    self.TU = nn.ConvTranspose2d(input_channels,output_channels, kernel_size=2, stride=2 , padding=0)\n    \n  def forward(self,x):\n    out = self.TU(x)\n    return out  \n    \n####################################################################################################\n\n############ Decoder block is used in reveal network ro extract secret image #############\nclass Decoder_block(nn.Module): \n  def __init__(self, input_channels , output_channels):\n    super(Decoder_block, self).__init__()\n    self.DecoderBlock = nn.Sequential(nn.Conv2d(input_channels , output_channels , kernel_size=3 , padding =1 ,stride=1),\n                            nn.BatchNorm2d(output_channels),\n                            nn.ReLU())\n    \n  def forward(self,x):\n    out = self.DecoderBlock(x)\n    return out      \n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:43.677658Z","iopub.execute_input":"2022-07-13T06:09:43.677913Z","iopub.status.idle":"2022-07-13T06:09:43.695754Z","shell.execute_reply.started":"2022-07-13T06:09:43.677884Z","shell.execute_reply":"2022-07-13T06:09:43.695063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ Defining Hidden Network by using the classes which are defined previously #############\n\nclass Hidden_Network(nn.Module):\n  def __init__(self):\n    super(Hidden_Network,self).__init__()\n    self.conv1 = nn.Conv2d( 6, 48, kernel_size = 3 , padding = 'same')\n    self.DB1   = DenseNet (48,12,4)\n    self.TD1   = Transition_Down(144,96)\n    self.DB2   = DenseNet (96,12,4)\n    self.TD2   = Transition_Down(240,144)\n    self.DB3   = DenseNet (144,12,4)\n    self.TD3   = Transition_Down(336,192)\n    self.DB4   = DenseNet (192,12,4)\n    self.TD4   = Transition_Down(432,240)\n    self.DB5   = DenseNet (240,12,4)\n    self.TD5   = Transition_Down(528,288)\n    self.DB6   = DenseNet (288,12,4)\n    self.TU1   = Transition_Up (336,336)\n    self.DB7   = DenseNet (864,12,4)\n    self.TU2   = Transition_Up (912,112)\n    self.DB8   = DenseNet (544,12,4)\n    self.TU3   = Transition_Up (592,92)\n    self.DB9   = DenseNet (428,12,4)\n    self.TU4   = Transition_Up (476,76)\n    self.DB10  = DenseNet (316,12,4)\n    self.TU5   = Transition_Up (364,64)\n    self.DB11  = DenseNet (208,12,4)\n    self.conv2 = nn.Conv2d( 256, 3, kernel_size = 3 , padding = 'same')\n  def forward(self, input):\n    y   = self.conv1(input)\n    DB1 = self.DB1(y)\n    C1  = torch.cat((y, DB1), 1)\n    TD1 = self.TD1(C1)\n    DB2 = self.DB2(TD1)\n    C2  = torch.cat((DB2, TD1), 1)\n    TD2 = self.TD2(C2)\n    DB3 = self.DB3(TD2)\n    C3  = torch.cat((DB3, TD2), 1)\n    TD3 = self.TD3(C3)\n    DB4 = self.DB4(TD3)\n    C4  = torch.cat((DB4, TD3), 1)\n    TD4 = self.TD4(C4)\n    DB5 = self.DB5(TD4)\n    C5  = torch.cat((DB5, TD4), 1)\n    TD5 = self.TD5(C5)\n    DB6 = self.DB6(TD5)\n    TU1 = self.TU1(DB6)\n    C6  = torch.cat((TU1, C5), 1)\n    DB7 = self.DB7(C6)\n    TU2 = self.TU2(DB7)\n    C7  = torch.cat((TU2, C4), 1)\n    DB8 = self.DB8(C7)\n    TU3 = self.TU3(DB8)\n    C8  = torch.cat((TU3, C3), 1)\n    DB9 = self.DB9(C8)\n    TU4 = self.TU4(DB9)\n    C9  = torch.cat((TU4, C2), 1)\n    DB10= self.DB10(C9)\n    TU5 = self.TU5(DB10)\n    C10 = torch.cat((TU5, C1), 1)\n    DB11= self.DB11(C10)\n    output = self.conv2(DB11)\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:46.011167Z","iopub.execute_input":"2022-07-13T06:09:46.011724Z","iopub.status.idle":"2022-07-13T06:09:46.030715Z","shell.execute_reply.started":"2022-07-13T06:09:46.011686Z","shell.execute_reply":"2022-07-13T06:09:46.029360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########## Testing the Hidden Network ###########\na = torch.rand(1,6,256,256)\nHidden_Network().forward(a).shape\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T17:56:34.15642Z","iopub.execute_input":"2022-07-04T17:56:34.156768Z","iopub.status.idle":"2022-07-04T17:56:36.542232Z","shell.execute_reply.started":"2022-07-04T17:56:34.156734Z","shell.execute_reply":"2022-07-04T17:56:36.541254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ Defining Reveal Network by using the classes which are defined previously #############\n\nclass Reveal_Network(nn.Module):\n\n  def __init__(self):\n    super(Reveal_Network,self).__init__()\n    self.Decoder1 = Decoder_block(3,64)\n    self.Decoder2 = Decoder_block(64,128)\n    self.Decoder3 = Decoder_block(128,256)\n    self.Decoder4 = Decoder_block(256,128)\n    self.Decoder5 = Decoder_block(128,64)\n    self.conv1    = nn.Conv2d( 64 , 3 , kernel_size=3 , padding =1 ,stride=1)\n    self.sigmo    = nn.Sigmoid()\n\n  def forward(self, input):\n    Decoder1  = self.Decoder1(input)\n    Decoder2  = self.Decoder2(Decoder1)\n    Decoder3  = self.Decoder3(Decoder2)\n    Decoder4  = self.Decoder4(Decoder3)\n    Decoder5  = self.Decoder5(Decoder4)\n    output    = self.sigmo(self.conv1(Decoder5))\n    \n    return output","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:50.893532Z","iopub.execute_input":"2022-07-13T06:09:50.893818Z","iopub.status.idle":"2022-07-13T06:09:50.901161Z","shell.execute_reply.started":"2022-07-13T06:09:50.893786Z","shell.execute_reply":"2022-07-13T06:09:50.900468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########## Testing the Reveal Network ###########\na = torch.rand(1,3,256,256)\nReveal_Network().forward(a).shape","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:58.682032Z","iopub.execute_input":"2022-07-13T06:09:58.682386Z","iopub.status.idle":"2022-07-13T06:10:00.621944Z","shell.execute_reply.started":"2022-07-13T06:09:58.682346Z","shell.execute_reply":"2022-07-13T06:10:00.621312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Stegano_Network(nn.Module):\n\n  def __init__(self):\n    super(Stegano_Network,self).__init__()\n    self.hidden=Hidden_Network()\n    self.reveal=Reveal_Network()\n  def forward(self, input):\n    Stego = self.hidden(input)\n    revealed_image = self.reveal(Stego)\n    \n    return Stego,revealed_image","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:09:55.551489Z","iopub.execute_input":"2022-07-13T06:09:55.551754Z","iopub.status.idle":"2022-07-13T06:09:55.557406Z","shell.execute_reply.started":"2022-07-13T06:09:55.551725Z","shell.execute_reply":"2022-07-13T06:09:55.556290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderLoss(nn.Module):\n  def __init__(self):\n      super(EncoderLoss,self).__init__()\n        \n  def forward(self,carrier_image,stego_image):    \n      encoder_loss = (F.mse_loss(carrier_image,stego_image))\n      return encoder_loss\n\nclass DecoderLoss(nn.Module):\n  def __init__(self):\n      super(DecoderLoss,self).__init__()\n        \n  def forward(self,revealed_image,secret_image):\n      decoder_loss = (F.mse_loss(revealed_image,secret_image))\n      return decoder_loss\nclass SteganoLoss(nn.Module):\n  def __init__(self,decoder_weight):\n      super(SteganoLoss,self).__init__()\n      self.decoder_weight = decoder_weight\n        \n  def forward(self,carrier_image,stego_image,revealed_image,secret_image):\n      stegano_loss = (F.mse_loss(carrier_image,stego_image)) + (self.decoder_weight*(F.mse_loss(revealed_image,secret_image)))\n      return stegano_loss     \n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:10:04.163460Z","iopub.execute_input":"2022-07-13T06:10:04.164130Z","iopub.status.idle":"2022-07-13T06:10:04.171809Z","shell.execute_reply.started":"2022-07-13T06:10:04.164095Z","shell.execute_reply":"2022-07-13T06:10:04.170989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = ('cuda' if torch.cuda.is_available() else 'cpu')\nmymodel= Stegano_Network().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:10:08.855732Z","iopub.execute_input":"2022-07-13T06:10:08.856044Z","iopub.status.idle":"2022-07-13T06:10:14.609608Z","shell.execute_reply.started":"2022-07-13T06:10:08.855997Z","shell.execute_reply":"2022-07-13T06:10:14.608891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ncriterion_encoder=EncoderLoss()\ncriterion_decoder=DecoderLoss()\ncriterion = SteganoLoss(0.85)   # 0.75 is beta hyperparamete in the paper\nopt = torch.optim.Adam(mymodel.parameters())\n\nencoder_losses = [] # hidden Losses in different epochs\ndecoder_losses = [] # reveal Losses in different epochs\nlosses        = [] # whole network Losses in different epochs\n# carrier=[]\n# secret=[]\n# training_part = 0 # training_part = 0 : hidden network is being trianed //// training_part = 1 : reveal network is being trianed\nfor epoch in range(epochs):    \n    for batch_i, (carrier,secret) in enumerate(train_loader):\n        tic = time() # Start of epoch\n        # Train\n        mymodel = mymodel.train()\n        batch_losses = []\n        encoder_batch_losses = []\n        decoder_batch_losses = []\n        carrier=carrier.to(device)\n        secret = secret.to(device)\n        concatenated_input=torch.cat((carrier,secret),1)\n        concatenated_input = concatenated_input.to(device)\n        Stego_image,revealed_image = mymodel.forward(concatenated_input)\n        encoder_loss=criterion_encoder(carrier,Stego_image)\n        decoder_loss=criterion_decoder(revealed_image,secret)\n        opt.zero_grad()\n        loss = criterion.forward(Stego_image, carrier,revealed_image,secret)\n        loss.backward()\n        opt.step()\n        batch_losses.append(loss.item())\n        encoder_batch_losses.append(encoder_loss.item())\n        decoder_batch_losses.append(decoder_loss.item())\n\n    epoch_loss = np.mean(batch_losses)\n    encoder_epoch_loss = np.mean(encoder_batch_losses)\n    decoder_epoch_loss = np.mean(decoder_batch_losses)\n    losses.append(epoch_loss)\n    train_string = f\"Epoch : {epoch} // loss : {epoch_loss: 0.7f} // encoder_loss : {encoder_epoch_loss: 0.7f} // decoder_loss : {decoder_epoch_loss: 0.7f} \"\n    print(train_string )\n\n\n      # mymodel = mymodel.eval() ### To disable dropout\n      # # Validation\n      # batch_losses = []\n      # for batch_i, (inputs, _) in enumerate(test_loader):\n      #   inputs = inputs.to(device) # Images\n      #   size=inputs.size()\n      #   carrier=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n      #   secret=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n      #   concatenated_input=torch.empty(int(size[0]/2),2*size[1],size[2],size[3])\n      #   j=0\n      #   z=0\n      #   for i in range(len(inputs)):\n      #     if i%2 == 0 : \n      #       carrier[j]=inputs[i]\n      #       j=j+1\n      #     else :\n      #       secret[z]=inputs[i]\n      #       concatenated_input[z] = torch.cat((carrier[j-1],secret[z]),0)\n      #       z=z+1\n\n      #   concatenated_input = concatenated_input.to(device)\n      #   carrier=carrier.to(device)\n      #   secret=secret.to(device)\n      #   with torch.no_grad():\n      #     output = mymodel.forward(concatenated_input)\n      #     loss = criterion(output, carrier)\n      #     batch_losses.append(loss.item())\n\n      # epoch_loss = np.mean(batch_losses)\n      # val_losses.append(epoch_loss)\n      # toc = time() #End of epoch\n      # val_string = f\" ////////////// val_loss : {epoch_loss: 0.5f}, , time : {toc - tic: 0.1f}\"\n      \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T06:12:46.767766Z","iopub.execute_input":"2022-07-13T06:12:46.768030Z","iopub.status.idle":"2022-07-13T09:04:57.218375Z","shell.execute_reply.started":"2022-07-13T06:12:46.767999Z","shell.execute_reply":"2022-07-13T09:04:57.217121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epochs = 10\n# criterion_encoder=EncoderLoss()\n# criterion_decoder=DecoderLoss()\n# criterion = SteganoLoss(0.85)   # 0.75 is beta hyperparamete in the paper\n# opt = torch.optim.Adam(mymodel.parameters())\n\n# encoder_losses = [] # hidden Losses in different epochs\n# decoder_losses = [] # reveal Losses in different epochs\n# losses        = [] # whole network Losses in different epochs\n# # carrier=[]\n# # secret=[]\n# # training_part = 0 # training_part = 0 : hidden network is being trianed //// training_part = 1 : reveal network is being trianed\n# for epoch in range(epochs):\n#       for inputs in (train_loader):\n#         tic = time() # Start of epoch\n#         # Train\n#         mymodel = mymodel.train()\n#         batch_losses = []\n#         encoder_batch_losses = []\n#         decoder_batch_losses = []\n#         inputs = inputs.to(device) # Images\n#         size=inputs.size()\n#         carrier=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n#         secret=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n#         concatenated_input=torch.empty(int(size[0]/2),2*size[1],size[2],size[3])\n#         j=0\n#         z=0\n#         for i in range(len(inputs)):\n#               if i%2 == 0 : \n#                 carrier[j]=inputs[i]\n#                 j=j+1\n#               else :\n#                     secret[z]=inputs[i]\n#                     concatenated_input[z] = torch.cat((carrier[j-1],secret[z]),0)\n#                     z=z+1\n\n#         concatenated_input = concatenated_input.to(device)\n#         carrier=carrier.to(device)\n#         secret=secret.to(device)\n\n#         Stego_image,revealed_image = mymodel.forward(concatenated_input)\n#         encoder_loss=criterion_encoder(carrier,Stego_image)\n#         decoder_loss=criterion_decoder(revealed_image,secret)\n#         opt.zero_grad()\n#         loss = criterion.forward(Stego_image, carrier,revealed_image,secret)\n#         loss.backward()\n#         opt.step()\n#         batch_losses.append(loss.item())\n#         encoder_batch_losses.append(encoder_loss.item())\n#         decoder_batch_losses.append(decoder_loss.item())\n\n\n#       epoch_loss = np.mean(batch_losses)\n#       encoder_epoch_loss = np.mean(encoder_batch_losses)\n#       decoder_epoch_loss = np.mean(decoder_batch_losses)\n#       losses.append(epoch_loss)\n#       train_string = f\"Epoch : {epoch} // loss : {epoch_loss: 0.7f} // encoder_loss : {encoder_epoch_loss: 0.7f} // decoder_loss : {decoder_epoch_loss: 0.7f} \"\n\n\n#       # mymodel = mymodel.eval() ### To disable dropout\n#       # # Validation\n#       # batch_losses = []\n#       # for batch_i, (inputs, _) in enumerate(test_loader):\n#       #   inputs = inputs.to(device) # Images\n#       #   size=inputs.size()\n#       #   carrier=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n#       #   secret=torch.empty(int(size[0]/2),size[1],size[2],size[3])\n#       #   concatenated_input=torch.empty(int(size[0]/2),2*size[1],size[2],size[3])\n#       #   j=0\n#       #   z=0\n#       #   for i in range(len(inputs)):\n#       #     if i%2 == 0 : \n#       #       carrier[j]=inputs[i]\n#       #       j=j+1\n#       #     else :\n#       #       secret[z]=inputs[i]\n#       #       concatenated_input[z] = torch.cat((carrier[j-1],secret[z]),0)\n#       #       z=z+1\n\n#       #   concatenated_input = concatenated_input.to(device)\n#       #   carrier=carrier.to(device)\n#       #   secret=secret.to(device)\n#       #   with torch.no_grad():\n#       #     output = mymodel.forward(concatenated_input)\n#       #     loss = criterion(output, carrier)\n#       #     batch_losses.append(loss.item())\n\n#       # epoch_loss = np.mean(batch_losses)\n#       # val_losses.append(epoch_loss)\n#       # toc = time() #End of epoch\n#       # val_string = f\" ////////////// val_loss : {epoch_loss: 0.5f}, , time : {toc - tic: 0.1f}\"\n#       print(train_string )\n      \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T09:12:35.554387Z","iopub.execute_input":"2022-06-21T09:12:35.555055Z","iopub.status.idle":"2022-06-21T09:12:35.960807Z","shell.execute_reply.started":"2022-06-21T09:12:35.555001Z","shell.execute_reply":"2022-06-21T09:12:35.959396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(mymodel.state_dict(), '/content/drive/MyDrive/Saved_Stegano_model_onCIFAR100_ORG.pt')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n here you can use my saved model that I have sent just upload it to your colab and then write its directory\n here -> (torch.load(directory))\n'''\nmysaved_model=Stegano_Network()\nmysaved_model.load_state_dict(torch.load('/content/drive/MyDrive/Saved_Stegano_model_onCIFAR100_ORG.pt',map_location=torch.device('cpu')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############# Visual & Quantative evaluation ###############\n\n############# here we use our test images to evaluate our network #############\n\nMSE = DecoderLoss()\n\nfor batch_i, (inputs, _) in enumerate(test_loader):\n  x=inputs\n  break\nmymodel=mymodel.to('cpu')\nc1 = torch.cat((x[10],x[11]),0)  # test images have been selected randomly\nc2 = torch.cat((x[3],x[12]),0)\n\nc_reshape1=torch.reshape(c1,(1,6,256,256))\nc_reshape2=torch.reshape(c2,(1,6,256,256))\nstego1,revealed1=mymodel.forward(c_reshape1)\nstego2,revealed2=mymodel.forward(c_reshape2)\nstego_x1=stego1.detach()\nstego_x2=stego2.detach()\nrevealed_x1=revealed1.detach()\nrevealed_x2=revealed2.detach()\nsecret1 = torch.reshape(x[11],(1,3,256,256))\nsecret2 = torch.reshape(x[12],(1,3,256,256))\ncarrier1 = torch.reshape(x[10],(1,3,256,256))\ncarrier2 = torch.reshape(x[3],(1,3,256,256))\n\n''' \nQuantative evaluation methods :\n    MSE\n    PSNR\n    SSIM\n'''\n#### SSIM ###\nssim = StructuralSimilarityIndexMeasure()\nssim_r_s1= ssim(revealed1, secret1)\nssim_r_s2= ssim(revealed2, secret2)\nssim_c_s1= ssim(stego1, carrier1)\nssim_c_s2= ssim(stego2, carrier2)\n#### MSE  ###\nmse_r_S1 = MSE(revealed1, secret1)\nmse_r_S2 = MSE(revealed2, secret2)\nmse_c_S1 = MSE(stego1, carrier1)\nmse_c_S2 = MSE(stego2, carrier2)\n#### PSNR ### \nrevealed1_f = tf.image.convert_image_dtype(revealed1.detach().numpy(), tf.float32)\nrevealed2_f = tf.image.convert_image_dtype(revealed2.detach().numpy(), tf.float32)\nsecret1_f = tf.image.convert_image_dtype(secret1.detach().numpy(), tf.float32) \nsecret2_f = tf.image.convert_image_dtype(secret2.detach().numpy(), tf.float32) \nstego1_f = tf.image.convert_image_dtype(stego1.detach().numpy(), tf.float32)\nstego2_f = tf.image.convert_image_dtype(stego2.detach().numpy(), tf.float32)\ncarrier1_f = tf.image.convert_image_dtype(carrier1.detach().numpy(), tf.float32) \ncarrier2_f = tf.image.convert_image_dtype(carrier2.detach().numpy(), tf.float32) \n\npsnr_r_s1= tf.image.psnr(revealed1_f,secret1_f,max_val=1)\npsnr_r_s2= tf.image.psnr(revealed2_f,secret2_f,max_val=1)\npsnr_c_s1= tf.image.psnr(stego1_f,carrier1_f,max_val=1)\npsnr_c_s2= tf.image.psnr(stego2_f,carrier2_f,max_val=1)\n\nprint(f\" Carrier vs Stego :: ssim : {ssim_c_s1} , MSE : {mse_c_S1}  , PSNR : {psnr_c_s1} //// Revealed vs Secret :: ssim : {ssim_r_s1} , MSE : {mse_r_S1}  , PSNR : {psnr_r_s1}\")\nprint(f\" Carrier vs Stego :: ssim : {ssim_c_s2} , MSE : {mse_c_S2}  , PSNR : {psnr_c_s2} //// Revealed vs Secret :: ssim : {ssim_r_s2} , MSE : {mse_r_S2}  , PSNR : {psnr_r_s2}\")\n\nfig, ax = plt.subplots(1,4, figsize =(15,15))\nax[0].imshow(x[10].permute(1,2,0))\nax[1].imshow(x[11].permute(1,2,0))\nax[2].imshow(stego_x1[0].permute(1,2,0))\nax[3].imshow(revealed_x1[0].permute(1,2,0))\nax[0].set_title(\"Cover Image\")\nax[1].set_title(\"Secret Image\")\nax[2].set_title(\"Stego Image\")\nax[3].set_title(\"revealed Image\")\nfig, ax = plt.subplots(1,4, figsize =(15,15))\nax[0].imshow(x[3].permute(1,2,0))\nax[1].imshow(x[12].permute(1,2,0))\nax[2].imshow(stego_x2[0].permute(1,2,0))\nax[3].imshow(revealed_x2[0].permute(1,2,0))\nax[0].set_title(\"Cover Image\")\nax[1].set_title(\"Secret Image\")\nax[2].set_title(\"Stego Image\")\nax[3].set_title(\"revealed Image\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:09:03.513066Z","iopub.execute_input":"2022-07-13T09:09:03.513357Z","iopub.status.idle":"2022-07-13T09:09:11.020004Z","shell.execute_reply.started":"2022-07-13T09:09:03.513322Z","shell.execute_reply":"2022-07-13T09:09:11.019142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############# Visual & Quantative evaluation ###############\n\n############# here we use our test images to evaluate our network #############\n\nMSE = DecoderLoss()\n\nfor batch_i, (inputs, _) in enumerate(test_loader):\n  x=inputs\n  break\nmymodel=mymodel.to('cpu')\nc1 = torch.cat((x[10],x[11]),0)  # test images have been selected randomly\nc2 = torch.cat((x[3],x[12]),0)\n\nc_reshape1=torch.reshape(c1,(1,6,256,256))\nc_reshape2=torch.reshape(c2,(1,6,256,256))\nstego1,revealed1=mymodel.forward(c_reshape1)\nstego2,revealed2=mymodel.forward(c_reshape2)\nstego_x1=stego1.detach()\nstego_x2=stego2.detach()\nrevealed_x1=revealed1.detach()\nrevealed_x2=revealed2.detach()\nsecret1 = torch.reshape(x[11],(1,3,256,256))\nsecret2 = torch.reshape(x[12],(1,3,256,256))\ncarrier1 = torch.reshape(x[10],(1,3,256,256))\ncarrier2 = torch.reshape(x[3],(1,3,256,256))\n\n''' \nQuantative evaluation methods :\n    MSE\n    PSNR\n    SSIM\n'''\n#### SSIM ###\n# ssim = StructuralSimilarityIndexMeasure()\n# ssim_r_s1= ssim(revealed1, secret1)\n# ssim_r_s2= ssim(revealed2, secret2)\n# ssim_c_s1= ssim(stego1, carrier1)\n# ssim_c_s2= ssim(stego2, carrier2)\n#### MSE  ###\nmse_r_S1 = MSE(revealed1, secret1)\nmse_r_S2 = MSE(revealed2, secret2)\nmse_c_S1 = MSE(stego1, carrier1)\nmse_c_S2 = MSE(stego2, carrier2)\n#### PSNR ### \nrevealed1_f = tf.image.convert_image_dtype(revealed1.detach().numpy(), tf.float32)\nrevealed2_f = tf.image.convert_image_dtype(revealed2.detach().numpy(), tf.float32)\nsecret1_f = tf.image.convert_image_dtype(secret1.detach().numpy(), tf.float32) \nsecret2_f = tf.image.convert_image_dtype(secret2.detach().numpy(), tf.float32) \nstego1_f = tf.image.convert_image_dtype(stego1.detach().numpy(), tf.float32)\nstego2_f = tf.image.convert_image_dtype(stego2.detach().numpy(), tf.float32)\ncarrier1_f = tf.image.convert_image_dtype(carrier1.detach().numpy(), tf.float32) \ncarrier2_f = tf.image.convert_image_dtype(carrier2.detach().numpy(), tf.float32) \n\npsnr_r_s1= tf.image.psnr(revealed1_f,secret1_f,max_val=1)\npsnr_r_s2= tf.image.psnr(revealed2_f,secret2_f,max_val=1)\npsnr_c_s1= tf.image.psnr(stego1_f,carrier1_f,max_val=1)\npsnr_c_s2= tf.image.psnr(stego2_f,carrier2_f,max_val=1)\n\nprint(f\" Carrier vs Stego :: MSE : {mse_c_S1}  , PSNR : {psnr_c_s1} //// Revealed vs Secret ::  , MSE : {mse_r_S1}  , PSNR : {psnr_r_s1}\")\nprint(f\" Carrier vs Stego :: MSE : {mse_c_S2}  , PSNR : {psnr_c_s2} //// Revealed vs Secret :: , MSE : {mse_r_S2}  , PSNR : {psnr_r_s2}\")\n\nfig, ax = plt.subplots(1,4, figsize =(15,15))\nax[0].imshow(x[10].permute(1,2,0))\nax[1].imshow(x[11].permute(1,2,0))\nax[2].imshow(stego_x1[0].permute(1,2,0))\nax[3].imshow(revealed_x1[0].permute(1,2,0))\nax[0].set_title(\"Cover Image\")\nax[1].set_title(\"Secret Image\")\nax[2].set_title(\"Stego Image\")\nax[3].set_title(\"revealed Image\")\nfig, ax = plt.subplots(1,4, figsize =(15,15))\nax[0].imshow(x[3].permute(1,2,0))\nax[1].imshow(x[12].permute(1,2,0))\nax[2].imshow(stego_x2[0].permute(1,2,0))\nax[3].imshow(revealed_x2[0].permute(1,2,0))\nax[0].set_title(\"Cover Image\")\nax[1].set_title(\"Secret Image\")\nax[2].set_title(\"Stego Image\")\nax[3].set_title(\"revealed Image\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T09:13:13.922944Z","iopub.execute_input":"2022-07-13T09:13:13.923748Z","iopub.status.idle":"2022-07-13T09:13:22.209618Z","shell.execute_reply.started":"2022-07-13T09:13:13.923709Z","shell.execute_reply":"2022-07-13T09:13:22.205254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}